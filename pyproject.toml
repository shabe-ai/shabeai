[tool.poetry]
name = "shabeai"
version = "0.1.0"
description = ""
authors = ["Vigeash Gohbal <vigeash11@gmail.com>"]
packages = [{ include = "app" }]

[tool.poetry.dependencies]
python = ">=3.12"
fastapi = ">=0.110.0"
fastapi-users = ">=12.1.2"
fastapi-users-db-sqlmodel = ">=0.1.0"
sqlmodel = ">=0.0.14"
streamlit = ">=1.32.0"
plotly = ">=5.19.0"
pandas = ">=2.2.1"
python-dotenv = ">=1.0.1"
openai = ">=1.12.0"
requests = ">=2.31.0"
uvicorn = ">=0.27.1"
psycopg2-binary = "^2.9.10"

[tool.poetry.group.dev.dependencies]
pytest = "^8.2"
ruff = "^0.4"
pytest-cov = "^6.1.1"
pytest-asyncio = "^1.0.0"
httpx = "^0.28.1"
pytest-mock = "^3.14.1"
factory-boy = "^3.3.3"
sqlalchemy-utils = "^0.41.2"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "--cov=app --cov-report=term-missing"

[tool.ruff]
line-length = 88
target-version = "py312"
select = ["E", "F", "B", "I"]
ignore = []

[tool.coverage.run]
# Only measure the code we actually unit-test
omit = [
  "app/main.py",      # Streamlit entry-point
  "app/commands.py",  # chat commands â€“ exercised manually, not in CI
  "app/reports.py",   # plotting helpers
  "app/nl_router.py",
  "app/audit.py",
  "app/utils.py",
  "app/database.py",
  "app/db.py",
]

